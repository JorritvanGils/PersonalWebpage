{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MGI_Project_Group_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH1UTlmS0HGg"
      },
      "source": [
        "# GRS-34806 MGI Project\n",
        "## **1) Download the data**\n",
        "This template downloads the UCM data (both mono and multi-labels) in your local Colab environment. \n",
        "\n",
        "Write the notebook in such a way that it fully runs from start to end without further intervention  \n",
        "(i.e. do not change the directory structure manually in the mean time).\n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3yDAMR7WJiR"
      },
      "source": [
        "!pip install d2l==0.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZniYdzlfx-2D"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "! git clone https://git.wur.nl/lobry001/ucmdata.git\n",
        "os.chdir('ucmdata')\n",
        "\n",
        "with zipfile.ZipFile('UCMerced_LandUse.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('UCMImages')\n",
        "\n",
        "!mv UCMImages/UCMerced_LandUse/Images .\n",
        "!rm -rf UCMImages README.md  UCMerced_LandUse.zip\n",
        "!ls\n",
        "\n",
        "UCM_images_path = \"Images/\"\n",
        "Multilabels_path = \"LandUse_Multilabeled.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQtwQs_gjj8K"
      },
      "source": [
        "##**2) Preprocessing the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wap0KzcDkPEl"
      },
      "source": [
        "#### Extract labels and prepare classes data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UDWLqYrScvE"
      },
      "source": [
        "# Import pandas and load multilabels dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv(Multilabels_path, sep=\"\\t\")\n",
        "\n",
        "# Extract labels for each image\n",
        "labels = df[df.columns[0]].str.replace('\\d+', '')\n",
        "labels = pd.DataFrame(labels)\n",
        "\n",
        "# List the 21 classes\n",
        "classes = df[df.columns[0]].str.replace('\\d+', '').unique()\n",
        "\n",
        "# Assign values per label\n",
        "for i in range(len(classes)):\n",
        "  labels.loc[labels[labels.columns[0]].str.contains(classes[i]), \"value\"] = i\n",
        "\n",
        "# Convert floats to integer\n",
        "labels[\"value\"] = labels[\"value\"].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a1K0lqike13"
      },
      "source": [
        "#### Split function and split image numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUuLBpXqk6j2"
      },
      "source": [
        "# Generate list with all image numbers\n",
        "img_numbers = [\"%.2d\" % i for i in range(100)]\n",
        "\n",
        "# Define split function to split all images in even and odd numbers (1050/1050)\n",
        "def split_numbers(numbers): \n",
        "   divisionlist = [] \n",
        "   restlist = [] \n",
        "   for i in range(len(numbers)): \n",
        "      if (i % 5 == 0): \n",
        "         divisionlist.append(numbers[i]) \n",
        "      else: \n",
        "         restlist.append(numbers[i]) \n",
        "   return (restlist, divisionlist)\n",
        "\n",
        "# Assign even and odd image numbers for train and test split\n",
        "train_num, test_num = split_numbers(img_numbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LPYAhFwk7Xg"
      },
      "source": [
        "#### Split label numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93FbWJRglXDI"
      },
      "source": [
        "# Generate index list for all image labels\n",
        "label_numbers = [i for i in range(2100)]\n",
        "\n",
        "# Assign even and odd image numbers for train and test split (1050/1050)\n",
        "train_label_num, test_label_num = split_numbers(label_numbers)\n",
        "\n",
        "# Get corresponding label function\n",
        "def getLabel (labels, numbers):\n",
        "  img_label = []\n",
        "  for i in numbers:\n",
        "    img_label.append(labels[\"value\"][i])\n",
        "  return(img_label)\n",
        "\n",
        "# Select training and test labels\n",
        "train_labels = getLabel(labels, train_label_num)\n",
        "test_labels = getLabel(labels, test_label_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUI3iPtOkm4E"
      },
      "source": [
        "#### Function to put images in tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voJm_FoPjyJW"
      },
      "source": [
        "import os\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "def load_data (classes, ids):\n",
        "\n",
        "  image_ids = ids\n",
        "  imgs = []\n",
        "  # Assign values per label\n",
        "  for i in range(len(classes)):\n",
        "    label = classes[i]\n",
        "    img_folder = os.path.join(UCM_images_path, label + \"/\") #Images/agricultural/\n",
        "    \n",
        "    #This will convert the numpy array to a tensor\n",
        "    conversion = T.ToTensor()\n",
        "\n",
        "    for img_index in image_ids:\n",
        "      \n",
        "      #Load the tile and the corresponding ground truth.\n",
        "      img = io.imread(os.path.join(img_folder, label + str(img_index) + '.tif')).astype(np.float32)/255 #Images/agricultural/agricultural01.tif\n",
        "      imgs.append(conversion(img))\n",
        "      \n",
        "      #print(\"Working on image \" + classes[i] + str(img_index))\n",
        "      #print(\"\\nimgs has \" + str(len(imgs)) + \" images\")\n",
        "      #print(\"\\nThe first image of imgs has \" + str(imgs[0].shape) +\"\\n\")\n",
        "      #print(len(imgs))\n",
        "\n",
        "  return (imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H4TPB4akydK"
      },
      "source": [
        "#### Prepare training and test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZznDHEt3lDM"
      },
      "source": [
        "train_data = load_data(classes, train_num)\n",
        "test_data = load_data(classes, test_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGr97TJAIv_p"
      },
      "source": [
        "##3) Define dataset class and load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQgVAyR11yPI"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class UCMDataset(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    self.imgs = images\n",
        "    self.labs = labels\n",
        "    self.resize = T.Resize((256, 256))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.resize(self.imgs[idx].float())\n",
        "    lab = self.labs[idx]\n",
        "\n",
        "    return img, lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEBPqzTIlYxS"
      },
      "source": [
        "#### Prepare training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4egdQqzL10Wb"
      },
      "source": [
        "#augs = torchvision.transforms.Compose([\n",
        "    #torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\n",
        "#first line add 'transform=augs'\n",
        "#dataset = torchvision.datasets.CIFAR10(root=\"../data\", train=is_train,\n",
        "                                           #transform=augs, download=True)\n",
        "\n",
        "training_dataset = UCMDataset(train_data, train_labels)\n",
        "test_dataset = UCMDataset(test_data, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcP_PK37lngB"
      },
      "source": [
        "#### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ollN8q410Ou"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_iter = torch.utils.data.DataLoader(dataset = training_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_iter = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUQkDA7fvbDN"
      },
      "source": [
        "iterable_train_loader = enumerate(train_iter)\n",
        "iterable_test_loader = enumerate(test_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDUfO1IPnVbP"
      },
      "source": [
        "#### Visualise image with label. Check if they correspond"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl_CseTq147m"
      },
      "source": [
        "X, y = next(iter(train_iter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dn3Q75OYHta"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "sample_id = 0\n",
        "image = X[sample_id].permute(1,2,0)\n",
        "imgplot = plt.imshow(image)\n",
        "print(\"label = \" + str(classes[y[sample_id]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOYSuqsl4piU"
      },
      "source": [
        "## **4) Create model classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndSp6EoNnnMH"
      },
      "source": [
        "#### Basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBoBqNgrY3I-"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "#Basic model\n",
        "class Hypercolumns1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Hypercolumns1, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1)\n",
        "    self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(256, 384, kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.lin1 = nn.Linear(9216, 4096)\n",
        "    self.lin2 = nn.Linear(4096, 4096)\n",
        "    self.lin3 = nn.Linear(4096, 21)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    # print('Conv1 shape: '+str(x.shape))\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    # print('Conv2 shape: '+str(x.shape))\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu(x)\n",
        "    # print('Conv3 shape: '+str(x.shape))\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    x = self.relu(x)\n",
        "    # print('Conv4 shape: '+str(x.shape))\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.flatten(x)\n",
        "    # print('Conv5 shape: '+str(x.shape))\n",
        "\n",
        "    x = self.lin1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    # print('Lin1 shape: '+str(x.shape))\n",
        "\n",
        "    x = self.lin2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    # print('Lin2 shape: '+str(x.shape))\n",
        "\n",
        "    x = self.lin3(x)\n",
        "    # print('Lin3 shape: '+str(x.shape))\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GakkUjrinsGz"
      },
      "source": [
        "#### Model with batch normalization before activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVakVruf4tJ9"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "#Batch norm before relu\n",
        "class Hypercolumns2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Hypercolumns2, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1)\n",
        "    self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(256, 384, kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.bn1 = nn.BatchNorm2d(96)\n",
        "    self.bn2 = nn.BatchNorm2d(256)\n",
        "    self.bn3 = nn.BatchNorm2d(384)\n",
        "\n",
        "    self.lin1 = nn.Linear(9216, 4096)\n",
        "    self.lin2 = nn.Linear(4096, 4096)\n",
        "    self.lin3 = nn.Linear(4096, 21)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.flatten(x)\n",
        "\n",
        "    x = self.lin1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.lin2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.lin3(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrNF_JMJnwzG"
      },
      "source": [
        "#### Model with batch normalization after activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUdy7D2Mlnnx"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "#Batch norm after relu\n",
        "class Hypercolumns3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Hypercolumns3, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1)\n",
        "    self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(256, 384, kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.bn1 = nn.BatchNorm2d(96)\n",
        "    self.bn2 = nn.BatchNorm2d(256)\n",
        "    self.bn3 = nn.BatchNorm2d(384)\n",
        "\n",
        "    self.lin1 = nn.Linear(9216, 4096)\n",
        "    self.lin2 = nn.Linear(4096, 4096)\n",
        "    self.lin3 = nn.Linear(4096, 21)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.flatten(x)\n",
        "\n",
        "    x = self.lin1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.lin2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.lin3(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZhK72D-n4au"
      },
      "source": [
        "#### Define all three models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPZlNTX_5KUU"
      },
      "source": [
        "net_basic = Hypercolumns1()\n",
        "net_bn_bf = Hypercolumns2()\n",
        "net_bn_af = Hypercolumns3()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTmkCNJVn88V"
      },
      "source": [
        "#### Check the shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XETDQtECn8L1",
        "outputId": "dcf893ee-d24c-4f11-db0b-acf9e1f808be"
      },
      "source": [
        "batch = next(iterable_train_loader)\n",
        "#[1][0] = images [1][1] = labels\n",
        "output = net_basic(batch[1][0])\n",
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 21])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHKgj_LQ4yJF"
      },
      "source": [
        "## **5) Prepare funcions and classes for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmc4ihNNwfI7"
      },
      "source": [
        "#Set device\n",
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUbAbckunqWk"
      },
      "source": [
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = d2l.argmax(y_hat, axis=1)\n",
        "    cmp = d2l.astype(y_hat, y.dtype) == y\n",
        "    return float(d2l.reduce_sum(d2l.astype(cmp, y.dtype)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yff4AtAPwD_H"
      },
      "source": [
        "#add the sum over n variables\n",
        "class Accumulator: \n",
        "  def __init__(self, n):\n",
        "    self.data = [0.0] * n\n",
        "  def add(self, *args):\n",
        "    self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "  def reset(self):\n",
        "    self.data = [0.0] * len(self.data)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gHPehd3iWkV"
      },
      "source": [
        "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
        "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\"\"\"\n",
        "    if isinstance(net, torch.nn.Module):\n",
        "        net.eval()  # Set the model to evaluation mode\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "    # No. of correct predictions, no. of predictions\n",
        "    metric = Accumulator(2)\n",
        "    for X, y in data_iter:\n",
        "        if isinstance(X, list):\n",
        "            # Required for BERT Fine-tuning (to be covered later)\n",
        "            X = [x.to(device) for x in X]\n",
        "        else:\n",
        "            X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        metric.add(accuracy(net(X), y), d2l.size(y))\n",
        "    return metric[0] / metric[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtRf51VEiuRS"
      },
      "source": [
        "\n",
        "#### Model training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuDkzzVQrHyi"
      },
      "source": [
        "from d2l import torch as d2l\n",
        "\n",
        "def train_model(net, train_iter, test_iter, num_epochs, lr, device):\n",
        "    \"\"\"Train a model with a GPU.\"\"\"\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "    net.apply(init_weights)\n",
        "    print('training on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0,1],\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "    for epoch in range(num_epochs):\n",
        "        # Sum of training loss, sum of training accuracy, no. of examples\n",
        "        metric = Accumulator(3)\n",
        "        net.train()\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
        "            timer.stop()\n",
        "            train_l = metric[0] / metric[2]\n",
        "            train_acc = metric[1] / metric[2]\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,\n",
        "                             (train_l, train_acc, None))\n",
        "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
        "        animator.add(epoch + 1, (None, None, test_acc))\n",
        "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
        "          f'test acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
        "          f'on {str(device)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHMzYUH146uw"
      },
      "source": [
        "## **6) Train the models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccgmalAyHR1r"
      },
      "source": [
        "#### Basic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HewvZgfV2QT_"
      },
      "source": [
        "# Basic model:\n",
        "lr, num_epochs = 0.01, 200\n",
        "train_model(net=net_basic, train_iter=train_iter, test_iter=test_iter, num_epochs=num_epochs, lr=lr, device=try_gpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfYJpNASHPHv"
      },
      "source": [
        "#### Before relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs4mHryq2QND"
      },
      "source": [
        "# With batch normalization before relu\n",
        "lr, num_epochs = 0.01, 100\n",
        "train_model(net=net_bn_bf, train_iter=train_iter, test_iter=test_iter, num_epochs=num_epochs, lr=lr, device=try_gpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COXPgw7DHL9Q"
      },
      "source": [
        "#### After relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8O6NJV-2QBY"
      },
      "source": [
        "# With batch normalization after relu\n",
        "lr, num_epochs = 0.05, 100\n",
        "train_model(net=net_bn_af, train_iter=train_iter, test_iter=test_iter, num_epochs=num_epochs, lr=lr, device=try_gpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAsTTt5j5B2L"
      },
      "source": [
        "## **7) Visualize accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6yaVaUBO-NE"
      },
      "source": [
        "#### visualise predictions for a single batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8UR18ba_E9h"
      },
      "source": [
        "batch = next(iterable_test_loader)\n",
        "pred = net_bn_af(batch[1][0].to(try_gpu()))\n",
        "fig, axs = plt.subplots(batch_size, 1)\n",
        "fig.set_size_inches(15,5*batch_size)\n",
        "for i in range(batch_size):\n",
        "  axs[i].imshow(batch[1][0].permute(0,2,3,1)[i,:,:,:])\n",
        "  axs[i].set_title(\"Label = \" + str(classes[batch[1][1][i]]) + \"\\nPrediction = \" + str(classes[pred[i].max(0)[1]]))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxQv6Wp927Fd"
      },
      "source": [
        "#### Calculate accuracy for a single batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl_v1vgSY_yy"
      },
      "source": [
        "# Accuracy\n",
        "def Calc_Accuracy():\n",
        "  x = 0\n",
        "  for i in range(batch_size):\n",
        "    if str(classes[batch[1][1][i]]) == str(classes[pred[i].max(0)[1]]):\n",
        "      x = x + 1\n",
        "  result = str(x / batch_size * 100) + \"%\"\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWJ73Ct-bU3Y"
      },
      "source": [
        "# The test data isn't shuffled, so depending on the classes available in the batch\n",
        "# It will can give a higher or lower accuracy than expected.\n",
        "\n",
        "# batch = next(iterable_test_loader)\n",
        "# pred = net_bn_af(batch[1][0].to(try_gpu()))\n",
        "\n",
        "Accuracy = \"The accuracy = \" + Calc_Accuracy()\n",
        "Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiunEXMXn1-e"
      },
      "source": [
        "---\n",
        "---\n",
        "## **8) Multilabel classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD9VbSRQ36YC"
      },
      "source": [
        "#### Prepare and load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmjD8Zxun5XA"
      },
      "source": [
        "# Prepare multilabel dataframe\n",
        "multicolumns = df[df.columns[1:]]\n",
        "multicolumns = multicolumns.astype(np.float32)\n",
        "multicolumns = multicolumns.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU1_jtDfn8Wj"
      },
      "source": [
        "# Get corresponding multilabel function\n",
        "def getMultiLabel (labels, numbers):\n",
        "  img_label = []\n",
        "  for i in numbers:\n",
        "    img_label.append(multicolumns[i])\n",
        "  return(img_label)\n",
        "\n",
        "# Select training and test multilabels\n",
        "train_multilabels = getMultiLabel(multicolumns, train_label_num)\n",
        "test_multilabels = getMultiLabel(multicolumns, test_label_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiGJ1aBln-Hz"
      },
      "source": [
        "Multi_train = UCMDataset(train_data, train_multilabels)\n",
        "Multi_test = UCMDataset(test_data, test_multilabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQWotOo_n_f7"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "Multi_train_iter = torch.utils.data.DataLoader(dataset = Multi_train, batch_size = batch_size, shuffle = True)\n",
        "Multi_test_iter = torch.utils.data.DataLoader(dataset = Multi_test, batch_size = batch_size, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h2dRTzr3yxO"
      },
      "source": [
        "#### Basic model for 17 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5hk2I3Ob2GP"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "#Basic model multilabel\n",
        "class Hypercolumns_multi(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Hypercolumns_multi, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1)\n",
        "    self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(256, 384, kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.lin1 = nn.Linear(9216, 4096)\n",
        "    self.lin2 = nn.Linear(4096, 4096)\n",
        "    self.lin3 = nn.Linear(4096, 17)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.flatten(x)\n",
        "\n",
        "    x = self.lin1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.lin2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.lin3(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00RIP21xFPSv"
      },
      "source": [
        "#### Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEp8KMOQFOfp"
      },
      "source": [
        "net_multi = Hypercolumns_multi()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf-4GY9A33AE"
      },
      "source": [
        "#### Train model function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxl5-ZYtoBx1"
      },
      "source": [
        "def train_multi_model(net, train_iter, test_iter, num_epochs, lr, device):\n",
        "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "    net.apply(init_weights)\n",
        "    print('training on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    loss = nn.BCELoss()\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0,1],\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "    for epoch in range(num_epochs):\n",
        "        # Sum of training loss, sum of training accuracy, no. of examples\n",
        "        metric = Accumulator(3)\n",
        "        net.train()\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
        "            timer.stop()\n",
        "            train_l = metric[0] / metric[2]\n",
        "            train_acc = metric[1] / metric[2]\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,\n",
        "                             (train_l, train_acc, None))\n",
        "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
        "        animator.add(epoch + 1, (None, None, test_acc))\n",
        "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
        "          f'test acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
        "          f'on {str(device)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "givRTiSs3j_d"
      },
      "source": [
        "#### Check the shapes for inconsistenty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPCy7MpFYnPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40adb2e-528a-4a85-ad06-10b910f14589"
      },
      "source": [
        "X, y = next(iter(Multi_train_iter))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 256, 256])\n",
            "torch.Size([128, 17])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeWewW4vBIE"
      },
      "source": [
        "device = try_gpu()\n",
        "X.to(device)\n",
        "y_hat = net_multi(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o22OWq3D3GXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f5ec34-81ee-4acc-9b4c-ea8e04592ae4"
      },
      "source": [
        "y_hat.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF33fRrqFXaG"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZRTQUYMoEw2"
      },
      "source": [
        "lr, num_epochs = 0.05, 10\n",
        "train_multi_model(net=net_multi, train_iter=Multi_train_iter, test_iter=Multi_test_iter, num_epochs=num_epochs, lr=lr, device=try_gpu())\n",
        "\n",
        "# RuntimeError: The size of tensor a (128) must match the size of tensor b (17) at non-singleton dimension 1\n",
        "# Both tensors have the same input shape. Check the code blocks above. We couldn't figure out why this was the case"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}